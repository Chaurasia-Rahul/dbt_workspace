import dlt
import pyodbc
from sql_database import sql_database

def load_select_tables_from_database(pipeline_name,schema, resources) -> None:
    pipeline = dlt.pipeline(
        pipeline_name=pipeline_name, destination="postgres", dataset_name="multisource_data"
    )
    source = sql_database(schema=schema).with_resources(*resources)
    for resource in resources:
        table_name = f"{resource}_{schema}"
        info = pipeline.run(source,table_name=table_name, write_disposition="replace")
        print(info)
        
if __name__ == "__main__":
    # Read parameters from the text file
    with open("parameters.txt", "r") as file:
        lines = file.readlines()
        for line in lines:
            params = line.strip().split()
            pipeline_name, schema, resources = params[0], params[1], params[2:]
            load_select_tables_from_database(pipeline_name, schema, resources)



-------------------------------------------------------------------

import dlt
import pyodbc
from sql_database import sql_database

def load_select_tables_from_database(pipeline_name,schema, resources) -> None:
    pipeline = dlt.pipeline(
        pipeline_name=pipeline_name, destination="postgres", dataset_name="multisourcedata"
    )
    source = sql_database(schema=schema).with_resources(*resources)
    info = pipeline.run(source, write_disposition="replace")
    print(info)

if __name__ == "__main__":
    # Read parameters from the text file
    with open("parameters.txt", "r") as file:
        lines = file.readlines()
        for line in lines:
            params = line.strip().split()
            pipeline_name, schema, resources = params[0], params[1], params[2:]
            load_select_tables_from_database(pipeline_name, schema, resources)


--------------------------------------------------------------

import dlt
from sqlalchemy import create_engine,text
from sql_database import sql_database

def load_select_tables_from_database(pipeline_name,schema, resources) -> None:
    pipeline = dlt.pipeline(
        pipeline_name=pipeline_name, destination="postgres", dataset_name="multisource_data"
    )
    source = sql_database(schema=schema).with_resources(*resources)
    info = pipeline.run(source, write_disposition="replace")
    print(info)

if __name__ == "__main__":
    # Connect to the database and fetch parameters
    engine = create_engine("postgresql://loader:Rahul_1234@localhost:5432/sakila_wh")
    with engine.connect() as conn:
        query = text("""
            SELECT 
                pipeline_name,
                db_schema,
                STRING_AGG(resources, ', ') AS resources 
            FROM 
                dwh.param_table 
            GROUP BY 
                pipeline_name, db_schema
        """)
        result = conn.execute(query)
        rows = result.fetchall()
        print(rows)
    for row in rows:
        pipeline_name, schema, resources = row
        resources = resources.split(', ')
        load_select_tables_from_database(pipeline_name, schema, resources)


------------------------------------

import dlt
from sqlalchemy import create_engine,text
from sql_database import sql_database

def load_select_tables_from_database(pipeline_name,schema, resources) -> None:
    pipeline = dlt.pipeline(
        pipeline_name=pipeline_name, destination="postgres", dataset_name="test_load"
    )
    source = sql_database(schema=schema).with_resources(*resources)
    info = pipeline.run(source, table_name = f"{resources}_{schema}",write_disposition="replace")
    print(info)

if __name__ == "__main__":
    # Connect to the database and fetch parameters
    engine = create_engine("postgresql://loader:Rahul_1234@localhost:5432/sakila_wh")
    with engine.connect() as conn:
        query = text("""
            SELECT 
                pipeline_name,
                db_schema,
                resources 
            FROM 
                dwh.param_table 
        """)
        result = conn.execute(query)
        rows = result.fetchall()
        print(rows)
    for row in rows:
        pipeline_name, schema, resources = row
        resources = resources.split(', ')
        load_select_tables_from_database(pipeline_name, schema, resources)